{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only use TOT rows for players that moved teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resources\n",
    "# https://www.basketball-reference.com/leagues/NBA_2020_per_game.html\n",
    "# https://www.basketball-reference.com/leagues/NBA_2020_advanced.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the first iteration, we will drop players based off games played (GP)/minutes per game (MPG). In the future, we should not drop these players because GP/MPG can have edge cases where a player dramatically changes their GP/MPG for different reasons that we currently do not track e.g. new coach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 30  # night night"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge per-game and advanced-stats together\n",
    "per_game_data = pd.read_csv('data/per_game_stats/2020_2021_all_players_per_game_stats.csv')\n",
    "advanced_stats_data = pd.read_csv('data//advanced_stats/2020_2021_all_players_advanced_stats.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove extra rows of traded players\n",
    "Players that get traded mid-season will have X+2 extra rows, where X is the number of times they were traded  \n",
    "Example: Traded once = 3 total rows (i.e. 2 extra rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For players that got traded, use only rows where their team == \"TOT\" i.e. total\n",
    "# 1. Get players (Player-additional) that have Tm == \"TOT\"\n",
    "traded_players = per_game_data[per_game_data[\"Tm\"] == \"TOT\"][\"Player-additional\"]\n",
    "\n",
    "# 2. For each player found, remove rows where Tm != \"TOT\"\n",
    "per_game_data = per_game_data[~((per_game_data['Player-additional'].isin(traded_players)) & (per_game_data['Tm'] != \"TOT\"))]\n",
    "advanced_stats_data = advanced_stats_data[~((advanced_stats_data['Player-additional'].isin(traded_players)) & (advanced_stats_data['Tm'] != \"TOT\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix colliding features that represent different things\n",
    "# e.g.  minutes played (MP) in per-game data is essentially minutes played per game,\n",
    "#       opposed to advanced-stats representing total minutes played in the season\n",
    "# Applicable features: MP\n",
    "colliding_features = [\"MP\"]\n",
    "for col in colliding_features:\n",
    "    per_game_data = per_game_data.rename(columns={col: f\"{col}_pg\"})\n",
    "    advanced_stats_data = advanced_stats_data.rename(columns={col: f\"{col}_as\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge\n",
    "uniq_cols = list(per_game_data.columns.difference(advanced_stats_data.columns))\n",
    "uniq_cols.append(\"Player-additional\")  # add merge-on target\n",
    "merged = pd.merge(per_game_data[uniq_cols], advanced_stats_data, on=\"Player-additional\", how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features that will be used to fit the model\n",
    "# cols = ['2P', '2P%', '2PA', '3P', '3P%', '3PA', 'AST', 'BLK', 'DRB', 'FG',\n",
    "#       'FG%', 'FGA', 'FT', 'FT%', 'FTA', 'GS', 'MP_pg', 'ORB', 'PF', 'PTS',\n",
    "#       'STL', 'TOV', 'TRB', 'eFG%', 'Player-additional', 'Rk', 'Player', 'Pos',\n",
    "#       'Age', 'Tm', 'G', 'MP_as', 'PER', 'TS%', '3PAr', 'FTr', 'ORB%', 'DRB%',\n",
    "#       'TRB%', 'AST%', 'STL%', 'BLK%', 'TOV%', 'USG%', 'Unnamed: 19', 'OWS',\n",
    "#       'DWS', 'WS', 'WS/48', 'Unnamed: 24', 'OBPM', 'DBPM', 'BPM', 'VORP']\n",
    "# Removed Player-additional, Rk, Player, Tm, and other null/empty cols\n",
    "cols_to_use = ['2P', '2P%', '2PA', '3P', '3P%', '3PA', 'AST', 'BLK', 'DRB', 'FG',\n",
    "               'FG%', 'FGA', 'FT', 'FT%', 'FTA', 'GS', 'MP_pg', 'ORB', 'PF', 'PTS',\n",
    "               'STL', 'TOV', 'TRB', 'eFG%', 'Pos',\n",
    "               'Age', 'G', 'MP_as', 'PER', 'TS%', '3PAr', 'FTr', 'ORB%', 'DRB%',\n",
    "               'TRB%', 'AST%', 'STL%', 'BLK%', 'TOV%', 'USG%', 'OWS',\n",
    "               'DWS', 'WS', 'WS/48', 'OBPM', 'DBPM', 'BPM', 'VORP', \"Player-additional\"]\n",
    "merged = merged[cols_to_use]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create target column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. load next season's per_game\n",
    "# 2. Calculate fan points for each row\n",
    "# 3. Merge into previous season's df\n",
    "next_season_per_game = pd.read_csv(\"data/per_game_stats/2021_2022_all_players_per_game_stats.csv\")\n",
    "\n",
    "# For players that got traded, use only rows where their team == \"TOT\" i.e. total\n",
    "# Get players (Player-additional) that have Tm == \"TOT\"\n",
    "traded_players = next_season_per_game[next_season_per_game[\"Tm\"] == \"TOT\"][\"Player-additional\"]\n",
    "\n",
    "# For each player found, remove rows where Tm != \"TOT\"\n",
    "next_season_per_game = next_season_per_game[~((next_season_per_game['Player-additional'].isin(traded_players)) & (next_season_per_game['Tm'] != \"TOT\"))]\n",
    "\n",
    "# Create target column\n",
    "fan_score_weights = {\n",
    "    \"point\": 1.0,\n",
    "    \"rebound\": 1.2,\n",
    "    \"assist\": 1.5,\n",
    "    \"steal\": 3.0,\n",
    "    \"block\": 3.0,\n",
    "    \"turnover\": -1.0,\n",
    "}\n",
    "next_season_per_game['avg_fantasy_points_next_season'] = (\n",
    "    (next_season_per_game['PTS'] * fan_score_weights[\"point\"])\n",
    "    + (next_season_per_game['TRB'] * fan_score_weights[\"rebound\"])\n",
    "    + (next_season_per_game['AST'] * fan_score_weights[\"assist\"])\n",
    "    + (next_season_per_game['STL'] * fan_score_weights[\"steal\"])\n",
    "    + (next_season_per_game['BLK'] * fan_score_weights[\"block\"])\n",
    "    + (next_season_per_game['TOV'] * fan_score_weights[\"turnover\"])\n",
    ")\n",
    "next_season_per_game = next_season_per_game[[\"Player-additional\", \"avg_fantasy_points_next_season\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = merged.merge(next_season_per_game, how=\"inner\", on=[\"Player-additional\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.sort_values(by=\"avg_fantasy_points_next_season\", ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Quality Check\n",
    "has_dupes = merged[\"Player-additional\"].duplicated().any()\n",
    "if has_dupes:\n",
    "    raise RuntimeError(\n",
    "        \"There are duplicate rows for a player. This likely means a player has multiple rows because they got traded, but our logic did not catch them\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Template for ML Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deciding which features are categorical\n",
    "# Select non-numeric (categorical) features\n",
    "non_numeric_features = merged.select_dtypes(include=['object', 'category'])\n",
    "features = list(non_numeric_features.columns)\n",
    "print(\n",
    "    f\"There are {len(list(non_numeric_features.columns))} features with object|category dtype\\n\"\n",
    "    f\"{'\\n'.join(list(non_numeric_features.columns))}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pos (i.e. Position) will definitely be OHE (One-Hot Encoded). I will also try a target encoding.  \n",
    "Player-additional will be dropped before training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.to_csv(\"merged.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe containing only the columns/features to use\n",
    "data = merged.copy()\n",
    "\n",
    "# Separate features and target variable\n",
    "X = data.drop(['avg_fantasy_points_next_season', \"Player-additional\", \"Pos\"], axis=1)  # Modify 'target_column_name' to your target column\n",
    "y = data['avg_fantasy_points_next_season']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling (if necessary)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize XGBoost regressor\n",
    "xgb = XGBRegressor(objective='reg:squarederror', random_state=RANDOM_STATE)  # You can adjust hyperparameters here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model on the training data\n",
    "xgb.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = xgb.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "r2 = r2_score(y_test, predictions)\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"R-squared (R2): {r2}\")\n",
    "\n",
    "# Cross-validation\n",
    "# Define the model and perform cross-validation\n",
    "model = XGBRegressor(objective='reg:squarederror')\n",
    "cv_scores = cross_val_score(model, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Convert scores to positive values\n",
    "cv_scores = -cv_scores\n",
    "\n",
    "# Calculate mean and standard deviation of cross-validation scores\n",
    "mean_cv_score = np.mean(cv_scores)\n",
    "std_cv_score = np.std(cv_scores)\n",
    "\n",
    "print(f\"Mean Cross-Validation Score (MSE): {mean_cv_score}\")\n",
    "print(f\"Standard Deviation of Cross-Validation Score (MSE): {std_cv_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i.e. The average difference between actual and predicted\n",
    "print(math.sqrt(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming y_true contains the actual target values and y_pred contains the predicted values\n",
    "# Create a DataFrame to store actual and predicted values side by side\n",
    "comparison_df = pd.DataFrame({'Actual': y_test, 'Predicted': predictions})\n",
    "\n",
    "# Print the DataFrame\n",
    "print(comparison_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nba_fantasy_12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
